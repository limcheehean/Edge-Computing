{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EENlZvOtPDZ6"
   },
   "source": [
    "# Quantization tutorial\n",
    "\n",
    "This tutorial shows how to do post-training static quantization, as well as illustrating two more advanced techniques - per-channel quantization and quantization-aware training - to further improve the model’s accuracy. The task is to classify MNIST digits with a simple LeNet architecture.\n",
    "\n",
    "\n",
    "Thsi is a mimialistic tutorial to show you a starting point for quantisation in PyTorch. For theory and more in-depth explanations, Please check out: [Quantizing deep convolutional networks for efficient inference: A whitepaper\n",
    "](https://arxiv.org/abs/1806.08342).\n",
    "\n",
    "The tutorial is heavily adapted from: https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTvIwDlYvBzC"
   },
   "source": [
    "### Initial Setup\n",
    "\n",
    "Before beginning the assignment, we import the MNIST dataset, and train a simple convolutional neural network (CNN) to classify it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbiiMcdNJI--",
    "outputId": "b03a637b-c757-47d9-ff23-1846dfe8c63b",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:37:42.443139Z",
     "start_time": "2025-02-28T07:37:35.803872Z"
    }
   },
   "source": [
    "!pip3 install torch==1.5.0 torchvision==1.6.0\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.quantization\n",
    "from torch.quantization import QuantStub, DeQuantStub"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.5.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for torch==1.5.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCaMDWYArEXO"
   },
   "source": [
    "Load training and test data from the MNIST dataset and apply a normalizing transformation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5UuOjjrnogR",
    "outputId": "f91bf88b-1f86-4777-d3cc-4ff31f629fbe",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:38:22.144485Z",
     "start_time": "2025-02-28T07:38:04.543172Z"
    }
   },
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=16, pin_memory=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:07<00:00, 1.38MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 121kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.41MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.49MB/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG5qXPDxnUnj"
   },
   "source": [
    "Define some helper functions and classes that help us to track the statistics and accuracy with respect to the train/test data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WetzHpQybN1k",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:38:48.641522Z",
     "start_time": "2025-02-28T07:38:48.633966Z"
    }
   },
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def accuracy(output, target):\n",
    "    \"\"\" Computes the top 1 accuracy \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        correct_one = correct[:1].view(-1).float().sum(0, keepdim=True)\n",
    "        return correct_one.mul_(100.0 / batch_size).item()\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    \"\"\" Prints the real size of the model \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "def load_model(quantized_model, model):\n",
    "    \"\"\" Loads in the weights into an object meant for quantization \"\"\"\n",
    "    state_dict = model.state_dict()\n",
    "    model = model.to('cpu')\n",
    "    quantized_model.load_state_dict(state_dict)\n",
    "\n",
    "def fuse_modules(model):\n",
    "    \"\"\" Fuse together convolutions/linear layers and ReLU \"\"\"\n",
    "    torch.quantization.fuse_modules(model, [['conv1', 'relu1'],\n",
    "                                            ['conv2', 'relu2'],\n",
    "                                            ['fc1', 'relu3'],\n",
    "                                            ['fc2', 'relu4']], inplace=True)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l62CkyIwtSOv"
   },
   "source": [
    "Define a simple CNN that classifies MNIST images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9fL3F-7Rntog",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:38:53.266587Z",
     "start_time": "2025-02-28T07:38:53.260447Z"
    }
   },
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, q = False):\n",
    "        # By turning on Q we can turn on/off the quantization\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256, 120, bias=False)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
    "        self.q = q\n",
    "        if q:\n",
    "          self.quant = QuantStub()\n",
    "          self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.q:\n",
    "          x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        # Be careful to use reshape here instead of view\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        if self.q:\n",
    "          x = self.dequant(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9_LdxSTb3BJ",
    "outputId": "540e9fbe-f3a4-416b-8938-de64035b7252",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:38:55.482602Z",
     "start_time": "2025-02-28T07:38:54.905308Z"
    }
   },
   "source": [
    "net = Net(q=False).cuda()\n",
    "print_size_of_model(net)"
   ],
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m net \u001B[38;5;241m=\u001B[39m \u001B[43mNet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m print_size_of_model(net)\n",
      "File \u001B[1;32m~\\Desktop\\Edge Computing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1053\u001B[0m, in \u001B[0;36mModule.cuda\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcuda\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, device: Optional[Union[\u001B[38;5;28mint\u001B[39m, device]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \n\u001B[0;32m   1039\u001B[0m \u001B[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1051\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m   1052\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1053\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Edge Computing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 903\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    905\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    906\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    907\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    908\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    913\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    914\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Edge Computing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    926\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    927\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    928\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    929\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 930\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    931\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    933\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Edge Computing\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1053\u001B[0m, in \u001B[0;36mModule.cuda.<locals>.<lambda>\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcuda\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, device: Optional[Union[\u001B[38;5;28mint\u001B[39m, device]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \n\u001B[0;32m   1039\u001B[0m \u001B[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1051\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m   1052\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1053\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(\u001B[38;5;28;01mlambda\u001B[39;00m t: \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\Desktop\\Edge Computing\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    308\u001B[0m     )\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    313\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    314\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nijieuxptag6"
   },
   "source": [
    "Train this CNN on the training dataset (this may take a few moments)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CzK6ohj5oNCT",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:38:59.660354Z",
     "start_time": "2025-02-28T07:38:59.653165Z"
    }
   },
   "source": [
    "def train(model: nn.Module, dataloader: DataLoader, cuda=False, q=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    model.train()\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = AverageMeter('loss')\n",
    "        acc = AverageMeter('train_acc')\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if epoch>=3 and q:\n",
    "              model.apply(torch.quantization.disable_observer)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss.update(loss.item(), outputs.shape[0])\n",
    "            acc.update(accuracy(outputs, labels), outputs.shape[0])\n",
    "            if i % 100 == 0:    # print every 100 mini-batches\n",
    "                print('[%d, %5d] ' %\n",
    "                    (epoch + 1, i + 1), running_loss, acc)\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "def test(model: nn.Module, dataloader: DataLoader, cuda=False) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            if cuda:\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "HixhBHaqtmZU",
    "outputId": "22964b09-97bf-46f3-e592-5f33755021eb",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:39:01.371686Z",
     "start_time": "2025-02-28T07:39:01.358851Z"
    }
   },
   "source": [
    "train(net, trainloader, cuda=True)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train(\u001B[43mnet\u001B[49m, trainloader, cuda\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'net' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJggxnCVuRxU"
   },
   "source": [
    "Now that the CNN has been trained, let's test it on our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y27_n-djuEdz",
    "outputId": "8e67d498-b18d-4be9-95fe-7e8706d23c9e",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:39:03.639628Z",
     "start_time": "2025-02-28T07:39:03.626178Z"
    }
   },
   "source": [
    "score = test(net, testloader, cuda=True)\n",
    "print('Accuracy of the network on the test images: {}% - FP32'.format(score))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m score \u001B[38;5;241m=\u001B[39m test(\u001B[43mnet\u001B[49m, testloader, cuda\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy of the network on the test images: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;132;01m% - F\u001B[39;00m\u001B[38;5;124mP32\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(score))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'net' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Lp-ElDsrKua"
   },
   "source": [
    "### Post-training quantization\n",
    "\n",
    "Define a new quantized network architeture, where we also define the quantization and dequantization stubs that will be important at the start and at the end.\n",
    "\n",
    "Next, we’ll “fuse modules”; this can both make the model faster by saving on memory access while also improving numerical accuracy. While this can be used with any model, this is especially common with quantized models."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X-nQWDXrhItv",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:39:08.876547Z",
     "start_time": "2025-02-28T07:39:08.860993Z"
    }
   },
   "source": [
    "qnet = Net(q=True)\n",
    "load_model(qnet, net)\n",
    "fuse_modules(qnet)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m qnet \u001B[38;5;241m=\u001B[39m Net(q\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 2\u001B[0m load_model(qnet, \u001B[43mnet\u001B[49m)\n\u001B[0;32m      3\u001B[0m fuse_modules(qnet)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'net' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiaQkj6wJuC6"
   },
   "source": [
    "In general, we have the following process (Post Training Quantization):\n",
    "\n",
    "1. Prepare: we insert some observers to the model to observe the statistics of a Tensor, for example, min/max values of the Tensor\n",
    "2. Calibration: We run the model with some representative sample data, this will allow the observers to record the Tensor statistics\n",
    "3. Convert: Based on the calibrated model, we can figure out the quantization parameters for the mapping function and convert the floating point operators to quantized operators"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-ZaMV4bUb6-",
    "outputId": "77098546-d269-44d8-a1b6-6d60cac12029",
    "ExecuteTime": {
     "end_time": "2025-02-28T07:39:24.546663Z",
     "start_time": "2025-02-28T07:39:10.922902Z"
    }
   },
   "source": [
    "qnet.qconfig = torch.quantization.default_qconfig\n",
    "print(qnet.qconfig)\n",
    "torch.quantization.prepare(qnet, inplace=True)\n",
    "print('Post Training Quantization Prepare: Inserting Observers')\n",
    "print('\\n Conv1: After observer insertion \\n\\n', qnet.conv1)\n",
    "\n",
    "test(qnet, trainloader, cuda=False)\n",
    "print('Post Training Quantization: Calibration done')\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print('Post Training Quantization: Convert done')\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
      "Post Training Quantization Prepare: Inserting Observers\n",
      "\n",
      " Conv1: After observer insertion \n",
      "\n",
      " Conv2d(\n",
      "  1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False\n",
      "  (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      ")\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      " Conv1: After fusion and quantization \n",
      "\n",
      " QuantizedConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.03629464656114578, zero_point=62, bias=False)\n",
      "Size of model after quantization\n",
      "Size (MB): 0.050084\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbDvGBtMavCO",
    "outputId": "9a1bb06b-dee0-4293-ac8a-05c4a13d7868",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-28T07:39:25.810320Z"
    }
   },
   "source": [
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcv6Gi45lZ4L"
   },
   "source": [
    "We can also define a cusom quantization configuration, where we replace the default observers and instead of quantising with respect to max/min we can take an average of the observed max/min, hopefully for a better generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNj6TNFu1ljn",
    "outputId": "054066c3-0c61-4a94-df74-3d6dcd71f328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
      "Post Training Quantization Prepare: Inserting Observers\n",
      "\n",
      " Conv1: After observer insertion \n",
      "\n",
      " ConvReLU2d(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (1): ReLU()\n",
      "  (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      " Conv1: After fusion and quantization \n",
      "\n",
      " QuantizedConvReLU2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.05865493789315224, zero_point=0, bias=False)\n",
      "Size of model after quantization\n",
      "Size (MB): 0.050084\n",
      "Accuracy of the fused and quantized network on the test images: 98.13% - INT8\n"
     ]
    }
   ],
   "source": [
    "from torch.quantization.observer import MovingAverageMinMaxObserver\n",
    "\n",
    "qnet = Net(q=True)\n",
    "load_model(qnet, net)\n",
    "fuse_modules(qnet)\n",
    "\n",
    "qnet.qconfig = torch.quantization.QConfig(\n",
    "                                      activation=MovingAverageMinMaxObserver.with_args(reduce_range=True),\n",
    "                                      weight=MovingAverageMinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
    "print(qnet.qconfig)\n",
    "torch.quantization.prepare(qnet, inplace=True)\n",
    "print('Post Training Quantization Prepare: Inserting Observers')\n",
    "print('\\n Conv1: After observer insertion \\n\\n', qnet.conv1)\n",
    "\n",
    "test(qnet, trainloader, cuda=False)\n",
    "print('Post Training Quantization: Calibration done')\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print('Post Training Quantization: Convert done')\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)\n",
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LXNCT7fgcMx"
   },
   "source": [
    "In addition, we can significantly improve on the accuracy simply by using a different quantization configuration. We repeat the same exercise with the recommended configuration for quantizing for arm64 architecture (qnnpack). This configuration does the following:\n",
    "Quantizes weights on a per-channel basis. It\n",
    "uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-nZq5yF_gWBs"
   },
   "outputs": [],
   "source": [
    "qnet = Net(q=True)\n",
    "load_model(qnet, net)\n",
    "fuse_modules(qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXv5pAwVlGFh",
    "outputId": "8a112f5f-020f-4138-eff9-7aaf9c463479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=False){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
      "Size of model after quantization\n",
      "Size (MB): 0.050084\n"
     ]
    }
   ],
   "source": [
    "qnet.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "print(qnet.qconfig)\n",
    "\n",
    "torch.quantization.prepare(qnet, inplace=True)\n",
    "test(qnet, trainloader, cuda=False)\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5Vjyayimv8n",
    "outputId": "2b63ad28-821e-4193-80c8-ff9ebbd3a30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the fused and quantized network on the test images: 98.02% - INT8\n"
     ]
    }
   ],
   "source": [
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A_G3tsasU6U"
   },
   "source": [
    "### Quantization aware training\n",
    "\n",
    "Quantization-aware training (QAT) is the quantization method that typically results in the highest accuracy. With QAT, all weights and activations are “fake quantized” during both the forward and backward passes of training: that is, float values are rounded to mimic int8 values, but all computations are still done with floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "o-mGba7QsXzf",
    "outputId": "c18ca8b2-0d3e-4abe-d89b-a98778395224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Conv1: After fusion and quantization \n",
      "\n",
      " ConvReLU2d(\n",
      "  1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False\n",
      "  (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
      "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False\n",
      "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
      "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
      "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      ")\n",
      "[1,     1]  loss 2.304440 (2.304440) train_acc 9.375000 (9.375000)\n",
      "[1,   101]  loss 2.295077 (2.302561) train_acc 23.437500 (11.958540)\n",
      "[1,   201]  loss 2.294279 (2.300279) train_acc 20.312500 (13.751555)\n",
      "[1,   301]  loss 2.288170 (2.297614) train_acc 18.750000 (16.190822)\n",
      "[1,   401]  loss 2.276252 (2.294031) train_acc 26.562500 (18.691552)\n",
      "[1,   501]  loss 2.260778 (2.289075) train_acc 37.500000 (22.080838)\n",
      "[1,   601]  loss 2.237988 (2.282447) train_acc 57.812500 (26.227121)\n",
      "[1,   701]  loss 2.189206 (2.272647) train_acc 60.937500 (29.981723)\n",
      "[1,   801]  loss 2.111011 (2.257459) train_acc 67.187500 (33.637640)\n",
      "[1,   901]  loss 1.935515 (2.232754) train_acc 71.875000 (37.179176)\n",
      "[2,     1]  loss 1.815505 (1.815505) train_acc 78.125000 (78.125000)\n",
      "[2,   101]  loss 1.518828 (1.718833) train_acc 81.250000 (70.327970)\n",
      "[2,   201]  loss 1.125992 (1.527937) train_acc 75.000000 (72.046020)\n",
      "[2,   301]  loss 0.826078 (1.338423) train_acc 81.250000 (73.411545)\n",
      "[2,   401]  loss 0.558374 (1.179151) train_acc 84.375000 (74.941552)\n",
      "[2,   501]  loss 0.396275 (1.057335) train_acc 87.500000 (76.515719)\n",
      "[2,   601]  loss 0.498701 (0.963201) train_acc 84.375000 (77.924813)\n",
      "[2,   701]  loss 0.374757 (0.888694) train_acc 89.062500 (79.130260)\n",
      "[2,   801]  loss 0.253134 (0.826470) train_acc 92.187500 (80.307818)\n",
      "[2,   901]  loss 0.281888 (0.772517) train_acc 90.625000 (81.407811)\n",
      "[3,     1]  loss 0.248566 (0.248566) train_acc 92.187500 (92.187500)\n",
      "[3,   101]  loss 0.350981 (0.317731) train_acc 87.500000 (90.841584)\n",
      "[3,   201]  loss 0.384525 (0.295504) train_acc 89.062500 (91.246891)\n",
      "[3,   301]  loss 0.380129 (0.282210) train_acc 87.500000 (91.491902)\n",
      "[3,   401]  loss 0.183598 (0.271671) train_acc 93.750000 (91.821228)\n",
      "[3,   501]  loss 0.197732 (0.261543) train_acc 92.187500 (92.159431)\n",
      "[3,   601]  loss 0.251078 (0.253413) train_acc 90.625000 (92.335691)\n",
      "[3,   701]  loss 0.266169 (0.243799) train_acc 89.062500 (92.611002)\n",
      "[3,   801]  loss 0.207979 (0.238297) train_acc 92.187500 (92.774657)\n",
      "[3,   901]  loss 0.239427 (0.232113) train_acc 95.312500 (92.966149)\n",
      "[4,     1]  loss 0.170995 (0.170995) train_acc 95.312500 (95.312500)\n",
      "[4,   101]  loss 0.225764 (0.173136) train_acc 89.062500 (94.755569)\n",
      "[4,   201]  loss 0.306369 (0.167502) train_acc 93.750000 (94.986007)\n",
      "[4,   301]  loss 0.109877 (0.163847) train_acc 96.875000 (95.187915)\n",
      "[4,   401]  loss 0.057776 (0.163052) train_acc 98.437500 (95.187812)\n",
      "[4,   501]  loss 0.173951 (0.161193) train_acc 95.312500 (95.215818)\n",
      "[4,   601]  loss 0.126010 (0.158190) train_acc 93.750000 (95.278702)\n",
      "[4,   701]  loss 0.120520 (0.155311) train_acc 95.312500 (95.310271)\n",
      "[4,   801]  loss 0.053902 (0.152130) train_acc 98.437500 (95.388577)\n",
      "[4,   901]  loss 0.165055 (0.149260) train_acc 93.750000 (95.463374)\n",
      "[5,     1]  loss 0.122501 (0.122501) train_acc 95.312500 (95.312500)\n",
      "[5,   101]  loss 0.033085 (0.117055) train_acc 100.000000 (96.163366)\n",
      "[5,   201]  loss 0.150807 (0.119394) train_acc 96.875000 (96.268657)\n",
      "[5,   301]  loss 0.162032 (0.120572) train_acc 93.750000 (96.246885)\n",
      "[5,   401]  loss 0.097207 (0.119384) train_acc 96.875000 (96.282731)\n",
      "[5,   501]  loss 0.109579 (0.116861) train_acc 96.875000 (96.369760)\n",
      "[5,   601]  loss 0.116021 (0.116181) train_acc 95.312500 (96.404430)\n",
      "[5,   701]  loss 0.164642 (0.115847) train_acc 95.312500 (96.406919)\n",
      "[5,   801]  loss 0.084875 (0.114979) train_acc 95.312500 (96.445849)\n",
      "[5,   901]  loss 0.054605 (0.114195) train_acc 98.437500 (96.457062)\n",
      "[6,     1]  loss 0.124124 (0.124124) train_acc 96.875000 (96.875000)\n",
      "[6,   101]  loss 0.056028 (0.099250) train_acc 98.437500 (97.107054)\n",
      "[6,   201]  loss 0.096668 (0.101031) train_acc 98.437500 (96.952736)\n",
      "[6,   301]  loss 0.125103 (0.099333) train_acc 96.875000 (96.978821)\n",
      "[6,   401]  loss 0.056739 (0.098409) train_acc 98.437500 (96.984102)\n",
      "[6,   501]  loss 0.074035 (0.098421) train_acc 98.437500 (97.005988)\n",
      "[6,   601]  loss 0.078242 (0.096662) train_acc 95.312500 (97.030990)\n",
      "[6,   701]  loss 0.020188 (0.095526) train_acc 100.000000 (97.051088)\n",
      "[6,   801]  loss 0.053327 (0.095198) train_acc 98.437500 (97.058365)\n",
      "[6,   901]  loss 0.066734 (0.095037) train_acc 96.875000 (97.072697)\n",
      "[7,     1]  loss 0.027886 (0.027886) train_acc 98.437500 (98.437500)\n",
      "[7,   101]  loss 0.019469 (0.081202) train_acc 100.000000 (97.602104)\n",
      "[7,   201]  loss 0.123808 (0.085864) train_acc 98.437500 (97.403607)\n",
      "[7,   301]  loss 0.130049 (0.085862) train_acc 95.312500 (97.383721)\n",
      "[7,   401]  loss 0.094753 (0.082690) train_acc 96.875000 (97.514027)\n",
      "[7,   501]  loss 0.113919 (0.082592) train_acc 96.875000 (97.464446)\n",
      "[7,   601]  loss 0.098542 (0.083274) train_acc 95.312500 (97.433964)\n",
      "[7,   701]  loss 0.008227 (0.083886) train_acc 100.000000 (97.447842)\n",
      "[7,   801]  loss 0.164467 (0.083901) train_acc 93.750000 (97.425094)\n",
      "[7,   901]  loss 0.055887 (0.082425) train_acc 98.437500 (97.473294)\n",
      "[8,     1]  loss 0.015187 (0.015187) train_acc 100.000000 (100.000000)\n",
      "[8,   101]  loss 0.047262 (0.073763) train_acc 98.437500 (97.679455)\n",
      "[8,   201]  loss 0.163617 (0.076628) train_acc 95.312500 (97.605721)\n",
      "[8,   301]  loss 0.046572 (0.077008) train_acc 98.437500 (97.622508)\n",
      "[8,   401]  loss 0.060605 (0.078516) train_acc 96.875000 (97.556889)\n",
      "[8,   501]  loss 0.147733 (0.076814) train_acc 96.875000 (97.604790)\n",
      "[8,   601]  loss 0.042546 (0.076574) train_acc 98.437500 (97.654950)\n",
      "[8,   701]  loss 0.062950 (0.075690) train_acc 96.875000 (97.675196)\n",
      "[8,   801]  loss 0.083476 (0.075734) train_acc 98.437500 (97.661127)\n",
      "[8,   901]  loss 0.075650 (0.074651) train_acc 98.437500 (97.710877)\n",
      "[9,     1]  loss 0.146265 (0.146265) train_acc 96.875000 (96.875000)\n",
      "[9,   101]  loss 0.095461 (0.061736) train_acc 93.750000 (98.035272)\n",
      "[9,   201]  loss 0.029066 (0.065671) train_acc 98.437500 (97.947761)\n",
      "[9,   301]  loss 0.037797 (0.065458) train_acc 98.437500 (97.918397)\n",
      "[9,   401]  loss 0.100056 (0.066495) train_acc 96.875000 (97.864713)\n",
      "[9,   501]  loss 0.039995 (0.067219) train_acc 98.437500 (97.869885)\n",
      "[9,   601]  loss 0.011912 (0.066606) train_acc 100.000000 (97.914933)\n",
      "[9,   701]  loss 0.227830 (0.067995) train_acc 95.312500 (97.900321)\n",
      "[9,   801]  loss 0.011241 (0.067192) train_acc 100.000000 (97.926420)\n",
      "[9,   901]  loss 0.022519 (0.067483) train_acc 100.000000 (97.946726)\n",
      "[10,     1]  loss 0.040864 (0.040864) train_acc 98.437500 (98.437500)\n",
      "[10,   101]  loss 0.122101 (0.060079) train_acc 98.437500 (98.097153)\n",
      "[10,   201]  loss 0.193999 (0.060114) train_acc 95.312500 (98.118781)\n",
      "[10,   301]  loss 0.145133 (0.062842) train_acc 98.437500 (98.074128)\n",
      "[10,   401]  loss 0.017767 (0.062216) train_acc 100.000000 (98.082918)\n",
      "[10,   501]  loss 0.061780 (0.063057) train_acc 96.875000 (98.060130)\n",
      "[10,   601]  loss 0.009336 (0.062604) train_acc 100.000000 (98.076123)\n",
      "[10,   701]  loss 0.053455 (0.062203) train_acc 96.875000 (98.092011)\n",
      "[10,   801]  loss 0.147072 (0.062073) train_acc 96.875000 (98.103933)\n",
      "[10,   901]  loss 0.033938 (0.061321) train_acc 100.000000 (98.130549)\n",
      "Finished Training\n",
      "Size of model after quantization\n",
      "Size (MB): 0.050084\n",
      "Accuracy of the fused and quantized network (trained quantized) on the test images: 98.0% - INT8\n"
     ]
    }
   ],
   "source": [
    "qnet = Net(q=True)\n",
    "fuse_modules(qnet)\n",
    "qnet.qconfig = torch.quantization.get_default_qat_qconfig('qnnpack')\n",
    "torch.quantization.prepare_qat(qnet, inplace=True)\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
    "qnet=qnet.cuda()\n",
    "train(qnet, trainloader, cuda=True)\n",
    "qnet = qnet.cpu()\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)\n",
    "\n",
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network (trained quantized) on the test images: {}% - INT8'.format(score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
